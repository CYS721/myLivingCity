{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad4e82cae7ad36d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T09:39:48.911212Z",
     "start_time": "2024-05-27T09:39:47.737376Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cd1d0721f3f57e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T09:48:28.014485Z",
     "start_time": "2024-05-27T09:48:28.009073Z"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "\n",
    "def generate_sentence(query):\n",
    "    # Construct the POST data as a dictionary\n",
    "    data = {\n",
    "        \"model\": \"llama3\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query\n",
    "            }\n",
    "        ],\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    # Convert dictionary to JSON format\n",
    "    json_data = json.dumps(data)\n",
    "\n",
    "    # Construct the curl command\n",
    "    curl_command = [\n",
    "        'curl',\n",
    "        'http://192.168.1.124:11434/api/chat',\n",
    "        '-d', json_data,\n",
    "        '-H', 'Content-Type: application/json'\n",
    "    ]\n",
    "\n",
    "    # Execute the curl command\n",
    "    process = subprocess.Popen(curl_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, error = process.communicate()\n",
    "\n",
    "    if process.returncode == 0:\n",
    "        return output\n",
    "    else:\n",
    "        return f\"Error: {error.decode('utf-8')}\"\n",
    "\n",
    "prompt = \"Given a sentence, analyze its tone as either 'Positive', 'Negative', or 'Neutral' and summarize the top keywords. Make sure Format your output as follows: 0. [Tone] | 1. [Attitude(verb)] | 2. [Keyword1] | 3. [Keyword2] | 4. [Keyword3] | 5. [Keyword4] | 6. [Keyword5]\\n Ensure that the keywords are relevant and capture the essence of the sentence. Try to identify the agents (action initiators) and patients (action recipients) in keywords. Do not explain or give any other content! Just seven tag! You only only only need to give me the tags. The sentence is: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97cc65cd1199fa1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:35:03.583540Z",
     "start_time": "2024-05-27T10:35:02.790891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718745\n"
     ]
    }
   ],
   "source": [
    "# show how many lines are in the file\n",
    "with open('GBcomments.csv') as f:\n",
    "    lines = f.readlines()\n",
    "    print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f68b6d7157739f06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-27T10:05:56.096119Z",
     "start_time": "2024-05-27T10:05:33.997876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yo ya me compre el iphone\n",
      "['Neutral', 'Got', 'iPhone', 'Me', 'Compre', 'Ya', '(None)']\n",
      "Songs\n",
      "['Neutral', 'Are', 'Songs', 'None', 'None', 'None', 'None']\n",
      "Eeee şimdi burda ne olcak , amaç ne\n",
      "['Negative', 'Worry', 'Burda', 'Olacak', 'Aimak', 'Ne', 'None', 'None']\n",
      "Good Job steve jobs RIP\n",
      "['Positive', 'Congratulate', 'Job', 'Steve', 'RIP', 'Good', '(None)', 'None']\n",
      "Good job. Plz watch realistic artwork. https://youtu.be/6HqJLy97Ras\n",
      "['Positive', 'Congratulate', 'Job', 'Watch', 'Realistic', 'Artwork', 'Video']\n",
      "Schlechtes iphone\n",
      "['Negative', 'Criticize', 'iPhone', 'Bad', 'None', 'None', 'None']\n",
      "https://youtu.be/Rt1Qx1HssQI\n",
      "['Neutral', 'Share', 'Video', 'YouTube', 'Link', 'None', 'None']\n",
      "OMG 25 hours\n",
      "['Negative', 'Exclaimed', 'Time', 'Hours', 'Long', 'Tired', 'Exhausted']\n",
      "same as samsang s8\n",
      "['Positive', 'Praising', 'Samsung', 'S8', 'Same', 'Phone', 'None', 'None']\n",
      "Fulckoing shoit mo8. Stolp copyinh Samsoung.\n",
      "['Negative', 'Criticizing', 'Samsung', 'Copying', 'Foul', 'Shoot', 'Stole', 'None']\n",
      "Eh c kii ce favoritisme lui il a tou led iphone apple watch ipad macbook en avance est gratuit wallah je reflechi a une idee poire wow on adore je suis riche mdrr sa arrivera q'au autre\n",
      "['Positive', 'Celebrate', 'iPhone', 'Apple', 'Favoritisme', 'Free', 'Rich']\n",
      "*#MamaDijo1VideoAntesDeLaCama*\n",
      "['Positive', 'Celebrates', 'Mama', 'Video', 'Camada', 'Before', 'La', 'Cama']\n",
      "25 Hours WTF\n",
      "['Negative', 'Expressing', 'Frustration', 'Time', 'Waste', 'Unbelievable', 'Exasperation']\n",
      "iPhone 6 cıkmış Way Ayku\n",
      "['Negative', 'Criticize', 'iPhone', 'Way', 'Ayku', 'Problems', 'None']\n",
      "snap.abood-1830\n",
      "['Neutral', 'Snap', 'None', 'None', 'None', 'None', 'None']\n",
      "Nadie vio este video completo 😂\n",
      "['Positive', 'Enjoyed', 'Video', 'Complete', 'Seen', 'None', 'None']\n",
      "The iPhone died with Steve Jobs\n",
      "['Negative', 'mourned', 'Steve', 'Jobs', 'iPhone', 'died', '(None)']\n",
      "https://m.facebook.com/questions.php?question_id=169339663628428 vote for lise Meitner gymnasium pleeaaaase\n",
      "['Positive', 'Request', 'Vote', 'Lise', 'Meitner', 'Gymnasium', 'Pleeeaaase', 'Please']\n",
      "Nice job\n",
      "['Positive', 'Praise', 'Job', 'Nice', '-', '-', '-']\n",
      "Yes now I can afford iphone 6\n",
      "['Positive', 'Can', 'Afford', 'iPhone', 'Now', 'I', '6']\n",
      ".\n",
      "['Neutral', 'Expresses', 'Feeling', 'Thoughts', 'Experience', 'Life', 'Moments']\n",
      "👎🏻👎🏻👎🏻👎🏻\n",
      "['Negative', 'Deplore', 'Disapproval', 'Frustration', 'Sadness', 'Despair', 'Discouragement']\n",
      "https://youtu.be/0acmdk_3bAQ\\nAbout iPhone\n",
      "['Positive', 'Praising', 'iPhone', 'About', 'Phone', 'Features', 'Devices', 'Technology']\n",
      "https://youtu.be/Pgv-Es9yvaM\n",
      "['Neutral', 'Show', 'Video', 'YouTube', 'Link', 'Share', 'URL']\n",
      "https://youtu.be/1VXcZU3iiQo\n",
      "['Neutral', 'Share', 'Video', 'Link', 'YouTube', 'URL', 'Online']\n",
      "fuck you beech\n",
      "['Is there something else I can help you with?']\n",
      "piece of shit\n",
      "['Negative', 'Curse', 'Shit', 'Piece', 'None', 'None', 'None']\n",
      "1 kidney =ıphone\n",
      "['Neutral', 'Compare', 'iPhone', 'Kidney', 'None', 'None', 'None', 'None']\n",
      "xDDD\n",
      "['Neutral', 'Expresses', 'Joy', 'Laughter']\n",
      "Steve Jobs :'v\n",
      "['Negative', 'Criticize', 'Jobs', 'Apple', 'Legacy', 'Controversy', 'Innovation']\n",
      "https://youtu.be/mWt_vudstiI\n",
      "['Neutral', 'Share', 'Video', 'Link', 'YouTube', 'None', 'None']\n",
      "Apple is always awesome \\n\\nhttps://youtu.be/rftzm6X1yP4\n",
      "['Positive', 'Praise', 'Awesome', 'Apple', 'Always', '', '', '']\n",
      "حتي الانجليزين يصور يقاعدو في الترند السعودي اف\n",
      "['Negative', 'Criticize', 'Saudi', 'English', 'Trend', 'Arabs', 'Nothing', 'None']\n",
      "الي عربي لايك ترا مو شحاذ لايكات\n",
      "['Negative', 'Complain', 'Arabic', 'Like', 'Trauma', 'Mo', 'Comments']\n",
      "Les francais ABONNEZ VOUS A LA CHAINE DE TIM SVP IL EST GENIAL\n",
      "['Positive', 'Invite', 'French', 'Channel', 'Tim', 'Genius', 'Subscribe', 'Please']\n",
      "Y habrá gente que se compre el puto iphone X, os creeis ricos o algo JAJAJAJAJ venga ya hombre que luego en casa comeis mierda por haberos comprado un movil de 1200 pavos, que sois unos moditas xd\n",
      "['Negative', 'Mock', 'iPhone', 'Money', 'Foolishness', 'Waste', 'Smartphone']\n",
      "Hallo wie geht's dir Tschüss bis nächstes Mal bye bye\n",
      "['Neutral', 'Saying', 'Hallo', 'Wie', 'Gehts', 'Dir', 'Bye', 'Mal']\n",
      "Cine-i moldovan  sau român pe aici?😂\n",
      "['Neutral', 'Wonder', 'Moldovan', 'Romanian', 'Here', 'Someone', 'None', 'None']\n",
      "Apple is terrible and they only care about the money\n",
      "['Negative', 'Blast', 'Apple', 'Terrible', 'Money', 'Care', 'Only', 'They']\n",
      "🖕 you Apple.  You make shitty products and hope you won't exist in 10 years time\n",
      "['Negative', 'Complain', 'Apple', 'Shitty', 'Products', 'Exist', 'Time']\n",
      "Does anyone have $1000\n",
      "['Neutral', 'Ask', 'Money', 'Anyone', 'Have', 'Thousand', 'Dollar', 'None']\n",
      "where is Steve Wozniak, fuck apple authority\n",
      "['Negative', 'Question', 'Apple', 'Authority', 'Steve', 'Where', 'Is', 'Fuck']\n",
      "dat price doh\n",
      "['Negative', 'Express', 'Price', 'Doth', 'None', 'None', 'None']\n",
      "Nice video 😘😘 \\n▶⏭Check my videos also ⏮◀\\n🔥🔥please subscribe  😊😊\n",
      "['Positive', 'Praise', 'Video', 'Check', 'Subscribe', 'Nice', 'Please', 'Subscribe']\n",
      "https://youtu.be/JI0ChkqKeOs\\napple iphone x hands on review\n",
      "['Positive', 'Praise', 'iPhone', 'Apple', 'Hands-on', 'Review', 'X', 'Experience']\n",
      "Ill have to sell me for this\n",
      "['Negative', 'Resist', 'Sell', 'Me', 'This', 'Have', 'To']\n",
      "Do all to Save the people muslims of burma\n",
      "['Positive', 'Call', 'Save', 'People', 'Muslims', 'Burma', 'None', 'None']\n",
      "where is iPhone 9?\n",
      "['Neutral', 'Seek', 'iPhone', 'Phone', 'None', 'None', 'None']\n",
      "Wow apples starting ideas from the galaxy now 🤔🤔\n",
      "['Positive', 'Excite', 'Ideas', 'Apples', 'Galaxy', 'Starting', '(None)', '(None)']\n",
      "birby\n",
      "['Neutral', 'Is', 'Birby', 'None', 'None', 'None', 'None']\n",
      "Fuck i want this !!! But i have no money\n",
      "['Negative', 'Express', 'Want', 'Money', 'None', 'None', 'None']\n",
      "Emma is 3rd on the trending page at the time of this comment, Whoop\n",
      "['Positive', 'Congratulate', 'Emma', 'Trending', 'Time', 'Comment', 'Whoop']\n",
      "I love genetics, and by extension this, but my parents won't let me do this because they think the people behind it will try and frame me for a crime... \\n\\n\\nYeah.\n",
      "['Negative', 'Resist', 'Genetics', 'Parents', 'Crime', 'Try', 'Frame']\n",
      "Emma i will find you and i will marry you. \\nCook for you,\\nGive you a massage when  you're tired,\\nListen to how your day was,\\nHug you, \\nAnd love you :) 😂😂😂\\nI know it sounds creepy af 😂\n",
      "['Positive', 'Promise', 'Find', 'Marry', 'Cook', 'Love', 'Hug', 'Listen']\n",
      "Well just seems like a total waste of money, why would anyone want to have their DNA on some companies database anyway, maybe she didn't think about that though.\\nHow does anyone know how that information will be used in the future? let's hope she doesn't decide to have a microchip implanted next.\n",
      "['Negative', 'Complain', 'Waste', 'DNA', 'Database', 'Information', 'Future', 'Microchip']\n",
      "A lot of people will be from North European countries because of Vikings, Danes, Saxons, Angles and Normans etc invading in the past a reproducing with each other\n",
      "['Positive', 'Will', 'People', 'Viking', 'Invading', 'Reproducing', 'Each', 'Other']\n",
      "And then I just didn't exist made me choke on my water\n",
      "['Negative', 'make', 'choke', 'water', 'exist', 'me', 'none', 'none']\n",
      "I've actually been using charcoal powder for a couple of months now and noticed a HUGE improvement with the whitening and general hygiene of my teeth. Here's a post from Facebook from the company that I buy from....\\n\\n***Do you want beautiful sparkling teeth naturally?!***\\nLimited time only offer ♡ www.cosmeticbenefit.com\n",
      "['Positive', 'noticed', 'charcoal', 'whitening', 'hygiene', 'improvement', 'teeth']\n",
      "The first Youtuber that time passed and actually got better\n",
      "['Neutral', 'Commented', 'Time', 'First', 'Youtuber', 'Better', 'Passed']\n",
      "Broadly Northwest European does not mean Scandinavian, it could mean British, Irish, French, Dutch, German etc or Scandinavian.\n",
      "['Neutral', 'Clarify', 'European', 'Scandinavian', 'British', 'French', 'Dutch', 'German']\n",
      "My prediction before watching video. You are 100% Canadian\n",
      "['Neutral', 'Expresses', 'Prediction', 'Video', 'Watching', 'Canadian', 'Before']\n",
      "awww no fart noise at the end? :(\n",
      "['Negative', 'Expresses', 'Fart', 'Noise', 'Awful', 'Sad', 'Disappointment']\n",
      "Do you know that your number 3 on trending👏🏻👏🏻\n",
      "['Positive', 'Celebrate', 'Trending', 'Know', 'You', 'Number', 'Three']\n",
      "I just clicked on this video to say fuck you for the clickbait title in my feed\n",
      "['Negative', 'Reacted', 'Clickbait', 'Title', 'Video', 'Feed', 'Frustrated', 'Anger']\n",
      "anyone know where i can get the shirt Emma is wearing??? i absolutely love it\n",
      "['Positive', 'Love', 'Shirt', 'Emma', 'Love', 'Absolutely', 'Where', 'Get']\n",
      "When she said yeah I have a lot of freckles I was like you have 10 (ish). THATS NOT A LOT OF FRECKLES\n",
      "['Negative', 'Teased', 'Freckles', 'Lot', 'Yeah', 'Said', 'Not', \"That's\"]\n",
      "Oh no she is going to live forever. Imagine all the salt she can spread.\n",
      "['Negative', 'Warns', 'Forever', 'Live', 'Salt', 'Spread', 'None', 'None']\n",
      "EMMA IS A SLIGHTLY YOUNGER JEN BARBER FROM THE IT CROWD AAAAAAAAHHH\n",
      "['Neutral', 'Refer', 'Emma', 'Jen', 'Barber', 'Crowd', 'Ahhh']\n",
      "I already know my DNA makeup, I looked at my clothes draw.\\n\\n\\n\\nWhat? Thats were I keep my *JEANS*\\n\\n\\nimsorryillgonow...\n",
      "['Neutral', 'Expresses', 'Jeans', 'Clothes', 'Know', 'Makeup', 'Draw']\n",
      "I haven't done this test, I am not a Youtuber with a lot of videos or viewers, I have no interest in being any of the previously mentioned. But what I do now is that I am Nordic, and damn proud of it :D\n",
      "['Positive', 'Emphasize', 'Proud', 'Nordic', 'Interest', 'Viewers', 'None', 'Damn']\n",
      "emma blackery more like ELLIE BLACKERY you know because in the last of us\n",
      "['Negative', 'Compare', 'Ellie', 'Last', 'Emma', 'Blackery', 'Know']\n",
      "I found ur book in tescos today and I also found Ryan higas's book (insert joke here)\n",
      "['Positive', 'Found', 'Book', \"Tesco's\", 'Ryan', \"Higa's\", 'Joke', 'Today']\n",
      "Emma's album was just shown on Apple  presentation live\n",
      "['Positive', 'Showed', 'Album', 'Apple', 'Presentation', 'Live', 'Emma', 'Just']\n",
      "Emma: I'm never gonna die! \\nMe:  Hahaha.. Wish I could say the same ;w; *sweats nervously\n",
      "['Negative', 'Expresses', 'Die', 'Wish', 'Nervously', 'Same', 'Sweats']\n",
      "No genetic markers for ANY hereditary disease, AND, genetically predisposed for superior muscle mass?\\n\\nTime to get some of that hot eugenics breeding action!\n",
      "['Negative', 'Mock', 'Eugenics', 'Breeding', 'Disease', 'Muscle', 'Genetic', 'Superior']\n",
      "Hi hi the reason you have so many Swedish viewers is because we're so antisocial and spend our lives on the internet\n",
      "['Neutral', 'Pointed', 'Swedish', 'Viewers', 'Internet', 'Reason', 'Lives']\n",
      "you're not intolerant to dairy you're just not a baby cow\n",
      "['Positive', 'poking', 'dairy', 'intolerance', 'cow', 'baby', 'none', 'none']\n",
      "Considering the history of these Isles it'd be unusual not to have any scandinavian, germanic or french markers in your DNA\n",
      "['Neutral', 'Suggests', 'History', 'DNA', 'Scandinavian', 'Germanic', 'French', 'Unusual']\n",
      "I love how she says 'attached' lol\n",
      "['Positive', 'Adore', 'Love', 'Attached', 'She', 'Says', 'Lol', 'How']\n",
      "you can keep looking at it , time to time. They will keep updating it.\n",
      "['Neutral', 'Are', 'Time', 'It', 'Updating', 'Keep', 'Looking']\n",
      "so since emma is never gonna die does that mean she'll just keep making videos forever? cuz that'd be something to see.\n",
      "['Neutral ', 'Wonder ', 'Emma ', 'Videos ', 'Forever ', 'Mean ', 'See']\n",
      "Give me a thumbs up down below! OK I'm going...\n",
      "['Neutral', 'Requesting', 'Thumbs', 'Up', 'Down', 'Below', 'Going']\n",
      "These tests are antirely useless and give you wrong or misleading answers. There are no Swedish, Britisch, German or French genes. People have moved thousands of years around the world and there was always a mixture of genes. So how could you say that a specific gene is British?  This is what the companies say: We compared your DNA results to the reference populations we currently have in our database and estimated which of these were most similar to you in terms of the genetic markers you carry. This doesn’t necessarily mean that you belong to these groups or are directly from these regions, but that these groups were a similar genetic match.\\nSo be careful what you think this test tells you.\n",
      "['Negative', 'Criticize', 'Tests', 'Gene', 'DNA', 'Company', 'Misleading']\n",
      "well the Vikings did pillage and shag their way through England for a few hundred years so you shouldn't be that surprised that a British person has at least some Scandinavian in them\n",
      "['Neutral', 'Suggest', 'Vikings', 'England', 'Scandinavian', 'Surprise', 'Person']\n",
      "Emma, Please get Dan to send his DNA to the same lab.\\n\\nIt's definitely not so they can make a Demma...no no no no.\n",
      "['Negative', 'Warned', 'Send', 'DNA', 'Lab', 'Emma', 'Dan', 'Demma']\n",
      "i was actually interested in this...and then you said how much it was lol\n",
      "['Negative', 'Disappointed', 'Interested', 'Said', 'Much', 'Lol', 'This', 'It']\n",
      "Yaay we're probably related then welcome to the Scandinavian family.\n",
      "['Positive', 'Welcome', 'Family', 'Related', 'Scandinavian', 'Then', 'Probably']\n",
      "Lol the asparagus one means you can likely smell that weird pee smell when someone eats asparagus. Not everyone notices a change in smell.\n",
      "['Negative', 'Make', 'Asparagus', 'Smell', 'Pee', 'Change', 'Notice', 'Notice']\n",
      "It's not that you can smell asparagus, it's asparagus pee\n",
      "['Negative', 'Ridicule', 'Asparagus', 'Pee', 'Smell', 'Urine', 'Not', 'That']\n",
      "Ashkenazi Jewish are jews originated from Europe (like me :D)\n",
      "['Neutral', 'Are', 'Ashkenazi', 'Jewish', 'Jews', 'Europe']\n",
      "i love the editing in this\n",
      "['Positive', 'Love', 'Editing', 'This']\n",
      "Just to know.. Ashkenazi Jewish is a Jewish that came from Europe or Spain, You're welcome.\n",
      "['Neutral', 'Expresses', 'Welcome', 'Ashkenazi', 'Jewish', 'Europe', 'Spain']\n",
      "its pretty flattering that everyone gets so excited when they find out theyre scandinavian\n",
      "['Positive', 'Excites', 'Flattering', 'Scandinavian', 'Everyone', 'Find', 'Excited', 'They']\n",
      "''why would i wanna taste myself''\n",
      "['Negative', 'Question', 'Wanna', 'Taste', 'Myself', 'None', 'None']\n",
      "I LOVE that t-shirt you're wearing!\n",
      "['Positive', 'Adore', 'Love', 'T-shirt', 'You', 'Wearing', 'That', 'Shirt']\n",
      "When someone's diet changes drastically, it substantially alters the makeup of bacterial flora and fauna in your digestive system. Genetics be damned in this case. You can think of it as waging bacterial genocide. This is how people become intolerant of foods they tolerated before.\n",
      "['Negative', 'Alters', 'Bacterial', 'Flora', 'Fauna', 'Genocide', 'Intolerant']\n",
      "Yes, us Swedes love you!\n",
      "['Positive', 'Adore', 'Love', 'Swedes', 'You', 'Us', 'Sweden', 'None']\n",
      "Wasn't 23&me in a huge scandal not to long ago because they weren't giving out accurate​ info on people's genetic health?\n",
      "['Negative', 'Criticized', 'Scandal', 'Accurate', 'Genetic', 'Health', 'Info']\n",
      "It is a conspiracy.... It is the NWO collecting everyone's generic data so they know who to clone and who to m\n",
      "['Negative', 'Accusing', 'Conspiracy', 'Data', 'Clone', 'Collecting', 'Know', 'Everyone']\n",
      "That´s why I adore you! You´r practically mine and Pewd´s relative! :)\n",
      "['Positive', 'Adore', 'You', 'Mine', 'Relative', 'Love', 'None', 'None']\n",
      "                                             comment      tone      attitude  \\\n",
      "0                          Yo ya me compre el iphone   Neutral           Got   \n",
      "1                                              Songs   Neutral           Are   \n",
      "2                Eeee şimdi burda ne olcak , amaç ne  Negative         Worry   \n",
      "3                            Good Job steve jobs RIP  Positive  Congratulate   \n",
      "4  Good job. Plz watch realistic artwork. https:/...  Positive  Congratulate   \n",
      "\n",
      "  keyword1 keyword2   keyword3 keyword4 keyword5  \n",
      "0   iPhone       Me     Compre       Ya   (None)  \n",
      "1    Songs     None       None     None     None  \n",
      "2    Burda   Olacak      Aimak       Ne     None  \n",
      "3      Job    Steve        RIP     Good   (None)  \n",
      "4      Job    Watch  Realistic  Artwork    Video  \n"
     ]
    }
   ],
   "source": [
    "# read the file line by line\n",
    "# create a dataframe with the new comment and the new comment words\n",
    "comment_tags_df = pd.DataFrame(columns=['comment', 'tone', 'attitude', 'keyword1', 'keyword2', 'keyword3', 'keyword4', 'keyword5'])\n",
    "with open('GBcomments.csv') as f:\n",
    "    lines = f.readlines()\n",
    "    # skip the first line and read the rest\n",
    "    # loop through the lines and print the first 5 lines\n",
    "    for line in lines[50:150]:\n",
    "        # print the process of the loop every 1000 lines\n",
    "        if lines.index(line) % 1000 == 0:\n",
    "            print(\"Processing line\", lines.index(line))\n",
    "        # skip the content before the first comma, do not use split\n",
    "        # skip the last two numbers which are the likes and replies\n",
    "        new_comment = line[line.index(',')+2:line.rindex(',')-3]\n",
    "        # print the first 5 lines\n",
    "        query = prompt + new_comment\n",
    "        response = generate_sentence(query)\n",
    "        response_data = json.loads(response)\n",
    "        response_content = response_data[\"message\"][\"content\"].split('\\n')[0].split(' | ')\n",
    "        new_comment_words = []\n",
    "        for item in response_content:\n",
    "            try:\n",
    "                new_comment_words.append(item.split('. ')[1])\n",
    "            except IndexError:  \n",
    "                continue  \n",
    "        print(new_comment)\n",
    "        print(new_comment_words)\n",
    "        # make sure the new comment words are 7 in length, if not, add \"None\" to the list, if more than 7, ignore the rest\n",
    "        if len(new_comment_words) < 7:\n",
    "            new_comment_words += ['None'] * (7 - len(new_comment_words))\n",
    "        elif len(new_comment_words) > 7:\n",
    "            new_comment_words = new_comment_words[:7]\n",
    "        # use concat to add the new comment and the new comment words to the dataframe\n",
    "        comment_tags_df = pd.concat([comment_tags_df, pd.DataFrame([[new_comment] + new_comment_words], columns=['comment', 'tone', 'attitude', 'keyword1', 'keyword2', 'keyword3', 'keyword4', 'keyword5'])], ignore_index=True)\n",
    "        \n",
    "# print the dataframe\n",
    "print(comment_tags_df.head())\n",
    "# store the dataframe in a csv file\n",
    "comment_tags_df.to_csv('GB_comment_tags.csv', index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "044cc11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import profanity_check\n",
    "\n",
    "def predict_profanity(comment):\n",
    "\n",
    "    new_comment_list = []\n",
    "    new_comment_list.append(comment)\n",
    "    if profanity_check.predict(new_comment_list)[0] == 1:\n",
    "        return 'Profane'\n",
    "    else:\n",
    "        return 'Not Profane'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36e7f372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Profane\n",
      "Profane\n"
     ]
    }
   ],
   "source": [
    "test_comment = \"I love this song, it's so good\"\n",
    "print(predict_profanity(test_comment))\n",
    "test_comment = \"I love this song, it's so shit awesome\"\n",
    "print(predict_profanity(test_comment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "384472cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_profanity_llm(comment):\n",
    "    prompt = \"Given a sentence, analyze whether it has bad words (profanity checking) or not. You should only return Profane or Not Profane. Don't explain anything!!! The sentence is: \"\n",
    "    query = prompt + comment\n",
    "    response = generate_sentence(query)\n",
    "    response_data = json.loads(response)\n",
    "    response_content = response_data[\"message\"][\"content\"]\n",
    "    return response_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4793a7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Profane\n",
      "Profane\n"
     ]
    }
   ],
   "source": [
    "test_comment = \"I love this song, it's so good\"\n",
    "print(predict_profanity_llm(test_comment))\n",
    "test_comment = \"I love this song, it's so fucking awesome\"\n",
    "print(predict_profanity_llm(test_comment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "862000a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Then go to the village pump and suggest they c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dis hoe wasnt dis violent on Lottery Ticket ðŸ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>It is better for Atabay not helping the banned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>is in CamelCase.  \"SiCKO\" is not CamelCase, so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nonetheless lactose has a hemiacetal group whi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tag                                            Content\n",
       "0    0  Then go to the village pump and suggest they c...\n",
       "1    1  Dis hoe wasnt dis violent on Lottery Ticket ðŸ...\n",
       "2    0  It is better for Atabay not helping the banned...\n",
       "3    0  is in CamelCase.  \"SiCKO\" is not CamelCase, so...\n",
       "4    0  Nonetheless lactose has a hemiacetal group whi..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profanity_df = pd.read_csv(\"demo.csv\",header=None)\n",
    "\n",
    "profanity_df = profanity_df.rename(columns={0: 'Tag', 1: 'Content'})\n",
    "profanity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dbbb708",
   "metadata": {},
   "outputs": [],
   "source": [
    "profanity_df['profanity check'] = profanity_df['Content'].apply(lambda x: predict_profanity(x))\n",
    "profanity_df['profanity check llm'] = profanity_df['Content'].apply(lambda x: predict_profanity_llm(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cb9fa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "profanity_df = profanity_df.reindex(columns=['Content', 'Tag', 'profanity check', 'profanity check llm'])\n",
    "profanity_df.head()\n",
    "profanity_df.to_csv(\"demo_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a068b4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
